diff --git a/hpu_graph_utils.py b/hpu_graph_utils.py
new file mode 100644
index 0000000..ef08c41
--- /dev/null
+++ b/hpu_graph_utils.py
@@ -0,0 +1,36 @@
+#!/usr/bin/env python3
+###############################################################################
+# Copyright (C) 2022 Habana Labs, Ltd. an Intel Company
+###############################################################################
+import torch
+
+
+class CachedParams:
+    def __init__(self, graph_inputs, graph_outputs, graph = None):
+        self.graph_inputs = graph_inputs
+        self.graph_outputs = graph_outputs
+        self.graph = graph
+
+
+def input_hash(obj):
+    if isinstance(obj, dict):
+        return input_hash(tuple(obj.items()))
+    elif isinstance(obj, list) or isinstance(obj, tuple):
+        return hash(tuple(input_hash(el) for el in obj))
+    elif torch.is_tensor(obj):
+        return hash(obj.shape)
+    else:
+        return hash(obj)
+
+
+def copy_to(dst, src):
+    assert type(dst) == type(src)
+    if isinstance(dst, dict):
+        for (dk, dv), (sk, sv) in zip(dst.items(), src.items()):
+            assert dk == sk
+            copy_to(dv, sv)
+    elif isinstance(dst, list) or isinstance(dst, tuple):
+        for d, s in zip(dst, src):
+            copy_to(d, s)
+    elif torch.is_tensor(dst):
+        dst.copy_(src)
diff --git a/ldm/models/diffusion/ddim.py b/ldm/models/diffusion/ddim.py
index aa3fbec..35f9a6d 100644
--- a/ldm/models/diffusion/ddim.py
+++ b/ldm/models/diffusion/ddim.py
@@ -9,11 +9,16 @@ from einops import rearrange
 from ldm.modules.diffusionmodules.util import make_ddim_sampling_parameters, make_ddim_timesteps, noise_like, extract_into_tensor
 from ldm.models.diffusion.sampling_util import renorm_thresholding, norm_thresholding, spatial_norm_thresholding
 
+import habana_frameworks.torch as ht
+import hpu_graph_utils
+
 
 class DDIMSampler(object):
     def __init__(self, model, schedule="linear", **kwargs):
         super().__init__()
         self.model = model
+        self.hpu_stream = ht.hpu.Stream()
+        self.cache = {}
         self.ddpm_num_timesteps = model.num_timesteps
         self.schedule = schedule
 
@@ -151,13 +156,17 @@ class DDIMSampler(object):
                 img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass?
                 img = img_orig * mask + (1. - mask) * img
 
+            capture = True
+            if i >= 2:
+                capture = False
+
             outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,
                                       quantize_denoised=quantize_denoised, temperature=temperature,
                                       noise_dropout=noise_dropout, score_corrector=score_corrector,
                                       corrector_kwargs=corrector_kwargs,
                                       unconditional_guidance_scale=unconditional_guidance_scale,
                                       unconditional_conditioning=unconditional_conditioning,
-                                      dynamic_threshold=dynamic_threshold)
+                                      dynamic_threshold=dynamic_threshold, capture=capture)
             img, pred_x0 = outs
             if callback: callback(i)
             if img_callback: img_callback(pred_x0, i)
@@ -168,15 +177,36 @@ class DDIMSampler(object):
 
         return img, intermediates
 
+    @torch.no_grad()
+    def capture_replay(self, x, t, c, capture):
+        inputs = [x, t, c]
+        h = hpu_graph_utils.input_hash(inputs)
+        cached = self.cache.get(h)
+        if capture:
+            with ht.hpu.stream(self.hpu_stream):
+                graph = ht.hpu.HPUGraph()
+                graph.capture_begin()
+                outputs = self.model.apply_model(inputs[0], inputs[1], inputs[2])
+                graph.capture_end()
+                graph_inputs = inputs
+                graph_outputs = outputs
+                self.cache[h] = hpu_graph_utils.CachedParams(graph_inputs, graph_outputs, graph)
+            return outputs
+
+        hpu_graph_utils.copy_to(cached.graph_inputs, inputs)
+        cached.graph.replay()
+        ht.core.hpu.default_stream().synchronize()
+        return cached.graph_outputs
+
     @torch.no_grad()
     def p_sample_ddim(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,
                       temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,
                       unconditional_guidance_scale=1., unconditional_conditioning=None,
-                      dynamic_threshold=None):
+                      dynamic_threshold=None, capture=False):
         b, *_, device = *x.shape, x.device
 
         if unconditional_conditioning is None or unconditional_guidance_scale == 1.:
-            e_t = self.model.apply_model(x, t, c)
+            e_t = self.capture_replay(x, t, c, capture)
         else:
             x_in = torch.cat([x] * 2)
             t_in = torch.cat([t] * 2)
@@ -194,7 +224,7 @@ class DDIMSampler(object):
                                 c[k]])
             else:
                 c_in = torch.cat([unconditional_conditioning, c])
-            e_t_uncond, e_t = self.model.apply_model(x_in, t_in, c_in).chunk(2)
+            e_t_uncond, e_t = self.capture_replay(x_in, t_in, c_in, capture).chunk(2)
             e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)
 
         if score_corrector is not None:
diff --git a/scripts/txt2img.py b/scripts/txt2img.py
index ffe82ec..3b05e16 100644
--- a/scripts/txt2img.py
+++ b/scripts/txt2img.py
@@ -258,7 +258,7 @@ def main():
 
                         if not opt.skip_save:
                             for x_sample in x_samples_ddim:
-                                x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')
+                                x_sample = 255. * rearrange(x_sample.to(torch.float32).cpu().numpy(), 'c h w -> h w c')
                                 Image.fromarray(x_sample.astype(np.uint8)).save(
                                     os.path.join(sample_path, f"{base_count:05}.png"))
                                 base_count += 1
